{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import estimate_bandwidth, MeanShift\n",
    "from PIL import Image\n",
    "\n",
    "def boundary(path_model, path_train, boundary_pts, size=(12,3)):\n",
    "    # Drawing the bounding box\n",
    "    img_train = cv2.imread(path_train) \n",
    "    img_rgb_train = cv2.cvtColor(img_train,cv2.COLOR_BGR2RGB)\n",
    "    img_rgb_train = cv2.polylines(img_rgb_train,boundary_pts,True,(0,180,0),8, cv2.LINE_AA)\n",
    "    \n",
    "    cof=(int(sum(boundary_pts[0][i][0][0] for i in range(0, 4))/4),int(sum(boundary_pts[0][i][0][1] for i in range(0, 4))/4))\n",
    "    shape=(min(abs(boundary_pts[0][0][0][0]-boundary_pts[0][3][0][0]),abs(boundary_pts[0][1][0][0]-boundary_pts[0][2][0][0])),min(abs(boundary_pts[0][1][0][1]-boundary_pts[0][0][0][1]),abs(boundary_pts[0][2][0][1]-boundary_pts[0][3][0][1])))\n",
    "    img_rgb_train = cv2.circle(img_rgb_train, cof, radius=10, color=(255, 0, 0), thickness=-1)\n",
    "    \n",
    "    img_model = cv2.imread(path_model) \n",
    "    img_rgb_model = cv2.cvtColor(img_model,cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    print(\"{Position: %s, width: %d, height: %d}\" % (str(cof),shape[0],shape[1]))\n",
    "    \n",
    "    f, axarr = plt.subplots(1,2,figsize=size)\n",
    "    axarr[0].imshow(img_rgb_train)\n",
    "    axarr[1].imshow(img_rgb_model)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def show_image(path, size=(20,4)):\n",
    "    img = cv2.imread(path)   \n",
    "    img_rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=size)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##LOCAL OPERATOR##\n",
    "\n",
    "#Gaussian\n",
    "def gaussian_filter(path, sigma=1.5):\n",
    "    k_size = int(np.ceil((3*sigma))*2 + 1) \n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_tr = cv2.GaussianBlur(img, (k_size,k_size) , sigma)\n",
    "    return img_tr\n",
    "\n",
    "#Bilateral Filter\n",
    "def bilateral_filter(path, k_size = 9, sigma1= 75, sigma2=75):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_bilateral = cv2.bilateralFilter(img,9,75,75)\n",
    "    return img_bilateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sift_cluster_recognition(path_model, sigma_model, path_train, sigma_train, min_match_count, quantile):\n",
    "    \n",
    "    #Gaussian\n",
    "    img_model_bw = gaussian_filter(path_model, sigma_model)\n",
    "    img_train_bw = gaussian_filter(path_train, sigma_train)\n",
    "            \n",
    "    #Bilateral\n",
    "    #img_model_bw = bilateral_filter(path_model)\n",
    "    #img_train_bw = bilateral_filter(path_train)\n",
    "    \n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(img_model_bw, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img_train_bw, None)\n",
    "\n",
    "    x = np.array([kp2[0].pt])\n",
    "\n",
    "    for i in range(len(kp2)):\n",
    "        x = np.append(x, [kp2[i].pt], axis=0)\n",
    "\n",
    "    x = x[1:len(x)]\n",
    "\n",
    "    bandwidth = estimate_bandwidth(x, quantile=quantile, n_samples=None, random_state=0)\n",
    "\n",
    "    ms = MeanShift(bandwidth=bandwidth, bin_seeding=True, cluster_all=True)\n",
    "    ms.fit(x)\n",
    "    labels = ms.labels_\n",
    "    cluster_centers = ms.cluster_centers_\n",
    "\n",
    "    labels_unique = np.unique(labels)\n",
    "    n_clusters_ = len(labels_unique)\n",
    "\n",
    "    s = [None] * n_clusters_\n",
    "    for i in range(n_clusters_):\n",
    "        l = ms.labels_\n",
    "        d, = np.where(l == i)\n",
    "        s[i] = list(kp2[xx] for xx in d)\n",
    "\n",
    "    des2_ = des2\n",
    "\n",
    "    for i in range(n_clusters_):\n",
    "\n",
    "        kp2 = s[i]\n",
    "        l = ms.labels_\n",
    "        d, = np.where(l == i)\n",
    "        des2 = des2_[d, ]\n",
    "\n",
    "        FLANN_INDEX_KDTREE = 0\n",
    "        index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "        search_params = dict(checks = 50)\n",
    "\n",
    "        flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "        des1 = np.float32(des1)\n",
    "        des2 = np.float32(des2)\n",
    "\n",
    "        matches = flann.knnMatch(des1, des2, 2)\n",
    "\n",
    "        # store all the good matches as per Lowe's ratio test.\n",
    "        good = []\n",
    "        for m,n in matches:\n",
    "            if m.distance < 0.7*n.distance:\n",
    "                good.append(m)\n",
    "\n",
    "        if len(good)>min_match_count:\n",
    "            src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "            dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "\n",
    "            M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 2)\n",
    "\n",
    "            if M is None:\n",
    "                print (\"No Homography\")\n",
    "            else:\n",
    "                print (\"Found in cluster %d the image %s - %d/%d\" % (i, path_model,len(good),min_match_count))\n",
    "                matchesMask = mask.ravel().tolist()\n",
    "                h,w = img_model_bw.shape\n",
    "                pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "                dst = cv2.perspectiveTransform(pts,M)\n",
    "                boundary_pts = [np.int32(dst)]\n",
    "                boundary(path_model, path_train, boundary_pts, size =(80,16))\n",
    "                #Eliminare il commento se si desidera eseguire il training per la parameters optimization\n",
    "                #createTable(path_train, path_model, boundary_pts, quantile, sigma_model, sigma_train, min_match_count, len(good))\n",
    "        #else:\n",
    "            #print (\"Not found in cluster %d the image %s - %d/%d\" % (i, path_model,len(good),min_match_count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK A\n",
    "USING SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imgs_train = ['scenes/e1.png', 'scenes/e2.png', 'scenes/e3.png', 'scenes/e4.png', 'scenes/e5.png']\n",
    "imgs_model = ['models/0.jpg', 'models/1.jpg', 'models/11.jpg', 'models/19.jpg', 'models/24.jpg', 'models/26.jpg', 'models/25.jpg']\n",
    "\n",
    "for path_train in imgs_train:\n",
    "    print(\"In the scene: \")\n",
    "    show_image(path_train, (20,4))\n",
    "    for path_model in imgs_model:\n",
    "        sift_cluster_recognition(path_model, 2.5, path_train, 1.5, 75, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK B USING SIFT AND CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_train = ['scenes/m1.png', 'scenes/m2.png', 'scenes/m3.png', 'scenes/m4.png', 'scenes/m5.png']\n",
    "imgs_model = ['models/0.jpg', 'models/1.jpg', 'models/11.jpg', 'models/19.jpg', 'models/24.jpg', 'models/26.jpg', 'models/25.jpg']\n",
    "\n",
    "for path_train in imgs_train:\n",
    "    print(\"In the scene: \")\n",
    "    show_image(path_train, (20,4))\n",
    "    for path_model in imgs_model:\n",
    "        sift_cluster_recognition(path_model, 2.0, path_train, 1.5, 90, 0.15)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK C BONUS\n",
    "USING SIFT AND CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_train = ['scenes/h1.jpg','scenes/h2.jpg', 'scenes/h3.jpg', 'scenes/h4.jpg', 'scenes/h5.jpg']\n",
    "\n",
    "for path_train in imgs_train:\n",
    "    print(\"In the scene: \")\n",
    "    show_image(path_train)\n",
    "    for i in range(0, 24):\n",
    "        sift_cluster_recognition(\"models/\"+str(i)+\".jpg\", 2.5, path_train, 0.4, 14, 0.035)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PARAMETERS OPTIMIZATION \n",
    "TRAINING IN TASK C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_img_train = 480\n",
    "width_img_train = 640\n",
    "table = pd.DataFrame(columns=['Scenes', 'Models', 'Quantile', 'Sigma_Model', 'Sigma_Train', 'MinMatchCount', 'Match', 'TP', 'FP'])\n",
    "table.to_csv(\"attempts/attempts_4.csv\", mode='a',index=False, header=True)\n",
    "\n",
    "def createTable(path_train, path_model, boundary_pts, quantile, sigma_model, sigma_train, min_match_count, good):\n",
    "    \n",
    "    table = pd.DataFrame(columns=['Scenes', 'Models', 'Quantile', 'Sigma_Model', 'Sigma_Train', 'MinMatchCount', 'Match', 'TP', 'FP'])\n",
    "\n",
    "    numCSV = path_train[8]\n",
    "    path_csv = \"centerScenes/h\"+numCSV+\".csv\"\n",
    "    df = pd.read_csv(path_csv, sep = ',', error_bad_lines=False) \n",
    "     \n",
    "    cof=(int(sum(boundary_pts[0][i][0][0] for i in range(0, 4))/4),int(sum(boundary_pts[0][i][0][1] for i in range(0, 4))/4))\n",
    "    \n",
    "    \n",
    "    df_Model = df[(df[\"Model\"] == i)]\n",
    "    ok = 0\n",
    "    for row in range(0,int(df_Model.shape[0])):\n",
    "        \n",
    "        x_Center = int(df_Model.iloc[row,1]*width_img_train) \n",
    "        y_Center = int(df_Model.iloc[row,2]*height_img_train)\n",
    "        width = int(df_Model.iloc[row,3]*width_img_train)\n",
    "        height = int(df_Model.iloc[row,4]*height_img_train)\n",
    "        \n",
    "        x1 = x_Center - (width/2)\n",
    "        x2 = x_Center + (width/2)\n",
    "        y1 = y_Center + (height/2)\n",
    "        y2 = y_Center - (height/2)\n",
    "        \n",
    "        if cof[0] < int(x2): \n",
    "            if cof[0] > int(x1):\n",
    "                if cof[1] < int(y1):\n",
    "                    if cof[1] > int(y2):\n",
    "                        ok = 1\n",
    "                  \n",
    "    if ok == 1:\n",
    "        truePositive = 1\n",
    "        falsePositive = 0\n",
    "    else:\n",
    "        truePositive = 0\n",
    "        falsePositive = 1\n",
    "        \n",
    "    newRow = { 'Scenes' : path_train, 'Models' : path_model, 'Quantile': quantile, 'Sigma_Model': sigma_model, 'Sigma_Train': sigma_train, 'MinMatchCount' : min_match_count, 'Match' : good, 'TP' : int(truePositive), 'FP' : int(falsePositive)}\n",
    "    table = table.append(newRow, ignore_index=True)\n",
    "    table.to_csv(\"attempts/attempts_4.csv\", mode='a',index=False, header=False)       \n",
    "\n",
    "for j in range(1,6):\n",
    "    path_train = \"scenes/h\"+str(j)+\".jpg\"\n",
    "    print(\"In the scene: \"+path_train)\n",
    "    for quantile in range(10,40,5):\n",
    "        for sigma_model in range(25,36,5):\n",
    "            for sigma_train in range(25,41,5):\n",
    "                for minMatch in range(13,15):\n",
    "                    for i in range(0, 24):\n",
    "                        quant = quantile/1000\n",
    "                        sigma_model_f = sigma_model/10\n",
    "                        sigma_train_f = sigma_train/100\n",
    "                        sift_cluster_recognition(\"models/\"+str(i)+\".jpg\", sigma_model_f, \"scenes/h\"+str(j)+\".jpg\", sigma_train_f, minMatch, quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = pd.DataFrame(columns=['Quantile', 'Sigma_Model', 'Sigma_Train', 'MinMatchCount', 'Sum TP', 'Sum FP'])\n",
    "\n",
    "df = pd.read_csv('attempts/attempts_3.csv', sep = ',', error_bad_lines=False) \n",
    "quantile = df[\"Quantile\"].unique()\n",
    "sigma_model = df[\"Sigma_Model\"].unique()\n",
    "sigma_Train = df[\"Sigma_Train\"].unique()\n",
    "minMatchCount = df[\"MinMatchCount\"].unique()\n",
    "for quant in quantile:\n",
    "    for sigmaM in sigma_model:\n",
    "        for sigmaT in sigma_Train:\n",
    "            for minMC in minMatchCount:\n",
    "                df_Parameters = df[(df['Quantile'] == quant) & (df['Sigma_Model'] == sigmaM) & (df['Sigma_Train'] == sigmaT)  & (df['MinMatchCount'] == minMC)]\n",
    "                sumTP = df_Parameters['TP'].sum()\n",
    "                sumFP = df_Parameters['FP'].sum()\n",
    "                relationship = sumTP - sumFP\n",
    "                newRow = { 'Quantile' : quant, 'Sigma_Model' : sigmaM, 'Sigma_Train': sigmaT, 'MinMatchCount' : minMC, 'Sum TP' : sumTP, 'Sum FP' : sumFP, 'Relationship' : relationship}\n",
    "                rank = rank.append(newRow, ignore_index=True)\n",
    "                rank = rank.sort_values(by='Relationship', ascending=False)\n",
    "\n",
    "rank.to_csv(\"rankings/rank_4.csv\", mode='w',index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
